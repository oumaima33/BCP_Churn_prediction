{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oumaima33/BCP_Churn_prediction/blob/main/BCP_Churn_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bank Customer Churn\n",
        "\n",
        "\n",
        "__Churner__ is generally defined as a customer who stops using a product or service for a given period of time.\n",
        "\n",
        "\n",
        "\n",
        "This notebook is to do the data analysis and predictions on the `Master table.csv` file."
      ],
      "metadata": {
        "id": "2bfvHuRc-Br8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eSWz_8x_OSQW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "194444ea-89c3-4a56-b6bb-eb518677a5cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CUb3YtQHcBKy"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col, sum, when"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AIbVWTL2OYXj"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Datacamp Pyspark Tutorial\") \\\n",
        "    .config(\"spark.memory.offHeap.enabled\", \"true\") \\\n",
        "    .config(\"spark.memory.offHeap.size\", \"10g\") \\\n",
        "    .config(\"spark.driver.memory\",\"32G\")\\\n",
        "    .config(\"spark.executer.memory\",\"32G\")\\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YpthKTbgOm2d"
      },
      "outputs": [],
      "source": [
        "master=spark.read.csv(\"/content/Master table.csv\",header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "E6j1MN39S5fl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c725d9c-7079-40d1-b0a6-0757238dc4e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+--------+--------------+---+---+--------------+---------+--------+-------+-------+--------+--------+--------------+---------------+-----------------+------------+----------+---------------+--------------+-----------------+------------+------------------+---------------+\n",
            "|Idclient|ANNEEMOIS|   genre|MARITAL_STATUS|BPR|age|CUSTOMER_YEARS|AGE_GROUP|   SOLDE| MVTDEB|NBMVTDB| MVTCRED|NBMVTCRE|MONTANTFACTURE|MONTANTVIREMENT|MONTANTOPERATIONS|NBROPERATION|MONTANTGAB|NBROPERATIONGAB|HasCreditYousr|ALREADY CONNECTED|ACTIVE_RATIO|CONNECTED RECENTLY|Churn_next_trim|\n",
            "+--------+---------+--------+--------------+---+---+--------------+---------+--------+-------+-------+--------+--------+--------------+---------------+-----------------+------------+----------+---------------+--------------+-----------------+------------+------------------+---------------+\n",
            "|       0|   201904| Féminin|      Marié(e)|  1| 64|            23|    55-64| 1025.33|3452.73|   9.33|  2500.0|     1.0|           0.0|            0.0|          1616.67|        1.33|   2133.33|           7.33|             0|                0|        NULL|                 0|              0|\n",
            "|       2|   201904| Féminin|      Marié(e)|  1| 70|            45|      65+| 5757.81| 7097.8|   2.67| 4100.77|     2.0|           0.0|            0.0|           1800.0|        1.67|   2666.67|           3.33|             0|                0|        NULL|                 0|              0|\n",
            "|       3|   201907| Féminin|   Celibataire|  1| 51|            17|    45-54| -881.56|  18.33|    0.0|     0.0|     0.0|           0.0|            0.0|              0.0|         0.0|       0.0|            0.0|             0|                0|        NULL|                 0|              0|\n",
            "|       4|   201904|Masculin|      Marié(e)|  1| 50|             6|    45-54|  236.91| 208.81|   3.67|   600.0|     1.0|           0.0|            0.0|              0.0|         0.0|     200.0|           0.67|             0|                0|        NULL|                 0|              0|\n",
            "|       4|   202001|Masculin|      Marié(e)|  1| 50|             6|    45-54|  143.16| 1013.2|   5.33|  1000.0|     1.0|           0.0|            0.0|              0.0|         0.0|       0.0|            0.0|             0|                0|        NULL|                 0|              0|\n",
            "|       5|   201904| Féminin|      Marié(e)|  1| 41|             9|    35-44| 4211.08|    0.0|    0.0|     0.0|     0.0|           0.0|            0.0|              0.0|         0.0|    3700.0|            3.0|             1|                1|     0.10896|                 0|              0|\n",
            "|       7|   201907| Féminin|   Celibataire|  1| 34|            12|    25-34| 5734.74|5293.04|    0.0|     0.0|     0.0|           0.0|            0.0|              0.0|         0.0|   1933.33|           2.33|             0|                0|         1.0|                 0|              0|\n",
            "|       9|   201904|Masculin|   Celibataire|  1| 39|             3|    35-44| 1006.83| 1545.0|    0.0|     0.0|     0.0|           0.0|            0.0|           533.33|        0.33|    866.67|           2.67|             0|                0|        NULL|                 0|              0|\n",
            "|      13|   202001|Masculin|   Celibataire|  1| 37|             6|    35-44| -777.28|  38.01|   1.33|     0.0|     0.0|           0.0|            0.0|              0.0|         0.0|       0.0|            0.0|             0|                0|        NULL|                 0|              0|\n",
            "|      14|   201910| Féminin|      Marié(e)|  1| 35|             4|    35-44| 2904.98|1047.07|   3.33| 2466.67|    1.33|           0.0|            0.0|              0.0|         0.0|   1833.33|           2.67|             0|                0|        NULL|                 0|              0|\n",
            "|      16|   201910| Féminin|   Celibataire|  1| 25|             7|    25-34|  535.23| 782.15|    0.0|     0.0|     0.0|           0.0|            0.0|              0.0|         0.0|       0.0|            0.0|             0|                0|        NULL|                 0|              0|\n",
            "|      17|   202001| Féminin|   Celibataire|  1| 26|             7|    25-34| 1646.97|  12.67|   0.67|  1600.0|     1.0|           0.0|            0.0|           2400.0|        1.33|   1366.67|           5.33|             0|                0|        NULL|                 0|              0|\n",
            "|      21|   201907|Masculin|      Marié(e)|  1| 43|             6|    35-44|   82.63|   11.0|   1.33|     0.0|     0.0|           0.0|            0.0|              0.0|         0.0|       0.0|            0.0|             0|                0|        NULL|                 0|              0|\n",
            "|      22|   201910|Masculin|   Celibataire|  1| 26|             3|    25-34| 3684.81|2776.67|   15.0| 5035.35|    4.67|           0.0|            0.0|              0.0|         0.0|       0.0|            0.0|             0|                0|        NULL|                 0|              0|\n",
            "|      25|   201910|Masculin|      Marié(e)|  1| 65|            24|      65+|     0.0|7684.21|    0.0|     0.0|     0.0|           0.0|            0.0|              0.0|         0.0|       0.0|            0.0|             0|                0|        NULL|                 0|              0|\n",
            "|      27|   201904|Masculin|      Marié(e)|  1| 70|             2|      65+|  453.39|3006.47|   4.33| 3041.79|    1.33|           0.0|            0.0|           1000.0|        0.33|       0.0|            0.0|             0|                0|        NULL|                 0|              0|\n",
            "|      29|   201910| Féminin|     Veuf (ve)|  1| 54|             9|    45-54|  784.07|  516.5|   2.67|  760.66|     1.0|           0.0|            0.0|              0.0|         0.0|    733.33|           1.33|             0|                0|        NULL|                 0|              0|\n",
            "|      34|   201904|Masculin|      Marié(e)|  1| 75|            23|      65+|   87.82|2449.27|   13.0| 2250.75|    3.33|           0.0|            0.0|          -183.33|        0.67|    166.67|            0.0|             0|                0|        NULL|                 0|              0|\n",
            "|      36|   202001| Féminin|   Celibataire|  1| 36|             4|    35-44|44903.94|   16.5|   1.33| 1211.88|    1.33|           0.0|            0.0|              0.0|         0.0|       0.0|            0.0|             0|                0|        NULL|                 0|              0|\n",
            "|      38|   201907|Masculin|   Celibataire|  1| 54|            22|    45-54|157585.4|    0.0|  11.67|20293.18|     3.0|           0.0|            0.0|        -32166.67|        0.67|    7500.0|           5.67|             0|                1|     0.20935|                 1|              0|\n",
            "+--------+---------+--------+--------------+---+---+--------------+---------+--------+-------+-------+--------+--------+--------------+---------------+-----------------+------------+----------+---------------+--------------+-----------------+------------+------------------+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "master.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "master.count()"
      ],
      "metadata": {
        "id": "UgoEJp_REQFd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "896cb4a5-e8d0-453c-a137-46a6b2781785"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3392620"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "m3mJ-M6zTFJJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a36d947-f7e6-46a8-d89a-2f329dc745a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Idclient: integer (nullable = true)\n",
            " |-- ANNEEMOIS: integer (nullable = true)\n",
            " |-- genre: string (nullable = true)\n",
            " |-- MARITAL_STATUS: string (nullable = true)\n",
            " |-- BPR: integer (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- CUSTOMER_YEARS: integer (nullable = true)\n",
            " |-- AGE_GROUP: string (nullable = true)\n",
            " |-- SOLDE: double (nullable = true)\n",
            " |-- MVTDEB: double (nullable = true)\n",
            " |-- NBMVTDB: double (nullable = true)\n",
            " |-- MVTCRED: double (nullable = true)\n",
            " |-- NBMVTCRE: double (nullable = true)\n",
            " |-- MONTANTFACTURE: double (nullable = true)\n",
            " |-- MONTANTVIREMENT: double (nullable = true)\n",
            " |-- MONTANTOPERATIONS: double (nullable = true)\n",
            " |-- NBROPERATION: double (nullable = true)\n",
            " |-- MONTANTGAB: double (nullable = true)\n",
            " |-- NBROPERATIONGAB: double (nullable = true)\n",
            " |-- HasCreditYousr: integer (nullable = true)\n",
            " |-- ALREADY CONNECTED: integer (nullable = true)\n",
            " |-- ACTIVE_RATIO: double (nullable = true)\n",
            " |-- CONNECTED RECENTLY: integer (nullable = true)\n",
            " |-- Churn_next_trim: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "master.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mf1d502zTLGE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05d5721d-0cc0-48fb-a0c0-bb8773b631a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+-----+--------------+---+---+--------------+---------+-----+------+-------+-------+--------+--------------+---------------+-----------------+------------+----------+---------------+--------------+-----------------+------------+------------------+---------------+\n",
            "|Idclient|ANNEEMOIS|genre|MARITAL_STATUS|BPR|age|CUSTOMER_YEARS|AGE_GROUP|SOLDE|MVTDEB|NBMVTDB|MVTCRED|NBMVTCRE|MONTANTFACTURE|MONTANTVIREMENT|MONTANTOPERATIONS|NBROPERATION|MONTANTGAB|NBROPERATIONGAB|HasCreditYousr|ALREADY CONNECTED|ACTIVE_RATIO|CONNECTED RECENTLY|Churn_next_trim|\n",
            "+--------+---------+-----+--------------+---+---+--------------+---------+-----+------+-------+-------+--------+--------------+---------------+-----------------+------------+----------+---------------+--------------+-----------------+------------+------------------+---------------+\n",
            "|       0|        0|    0|             0|  0|  0|             0|        0|    0|     0|      0|      0|       0|             0|              0|                0|           0|         0|              0|             0|                0|     3181536|                 0|              0|\n",
            "+--------+---------+-----+--------------+---+---+--------------+---------+-----+------+-------+-------+--------+--------------+---------------+-----------------+------------+----------+---------------+--------------+-----------------+------------+------------------+---------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "null_counts = master.select(*(sum(when(col(c).isNull(), 1).otherwise(0)).alias(c) for c in master.columns))\n",
        "\n",
        "null_counts.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-WJJUiNLdhI9"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col, max\n",
        "\n",
        "# Calculer la valeur maximale de la colonne ACTIVE_RATIO\n",
        "max_value = master.agg(max(col(\"ACTIVE_RATIO\"))).collect()[0][0]\n",
        "\n",
        "# Remplacer les valeurs nulles par la valeur maximale\n",
        "master = master.na.fill({\"ACTIVE_RATIO\": max_value})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3Gv_WdfcdmfG"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import to_date\n",
        "\n",
        "# Convertir la colonne 'ANNEEMOIS' en format de date avec le format 'yyyyMM'\n",
        "master = master.withColumn(\"ANNEEMOIS\", to_date(col(\"ANNEEMOIS\"), \"yyyyMM\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "y2u_7crjdyWb"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Convertir les colonnes 'Idclient' et 'BPR' en chaînes de caractères\n",
        "master = master.withColumn(\"Idclient\", col(\"Idclient\").cast(\"string\")) \\\n",
        "               .withColumn(\"BPR\", col(\"BPR\").cast(\"string\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yDA9nnVed5YP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f654d3e8-74bd-4a1d-edfc-1f6f660bd723"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Idclient: string (nullable = true)\n",
            " |-- ANNEEMOIS: date (nullable = true)\n",
            " |-- genre: string (nullable = true)\n",
            " |-- MARITAL_STATUS: string (nullable = true)\n",
            " |-- BPR: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- CUSTOMER_YEARS: integer (nullable = true)\n",
            " |-- AGE_GROUP: string (nullable = true)\n",
            " |-- SOLDE: double (nullable = true)\n",
            " |-- MVTDEB: double (nullable = true)\n",
            " |-- NBMVTDB: double (nullable = true)\n",
            " |-- MVTCRED: double (nullable = true)\n",
            " |-- NBMVTCRE: double (nullable = true)\n",
            " |-- MONTANTFACTURE: double (nullable = true)\n",
            " |-- MONTANTVIREMENT: double (nullable = true)\n",
            " |-- MONTANTOPERATIONS: double (nullable = true)\n",
            " |-- NBROPERATION: double (nullable = true)\n",
            " |-- MONTANTGAB: double (nullable = true)\n",
            " |-- NBROPERATIONGAB: double (nullable = true)\n",
            " |-- HasCreditYousr: integer (nullable = true)\n",
            " |-- ALREADY CONNECTED: integer (nullable = true)\n",
            " |-- ACTIVE_RATIO: double (nullable = false)\n",
            " |-- CONNECTED RECENTLY: integer (nullable = true)\n",
            " |-- Churn_next_trim: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "master.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zAkB9l6lfDx3"
      },
      "outputs": [],
      "source": [
        "master = master.filter(col(\"CUSTOMER_YEARS\") >= 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "7KJWKGcMiyJ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e77cfa52-90b8-4870-9cf4-9f6132bc413d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+--------+--------------+---+---+--------------+---------+--------+-------+-------+--------+--------+--------------+---------------+-----------------+------------+----------+---------------+--------------+-----------------+------------+------------------+---------------+\n",
            "|Idclient| ANNEEMOIS|   genre|MARITAL_STATUS|BPR|age|CUSTOMER_YEARS|AGE_GROUP|   SOLDE| MVTDEB|NBMVTDB| MVTCRED|NBMVTCRE|MONTANTFACTURE|MONTANTVIREMENT|MONTANTOPERATIONS|NBROPERATION|MONTANTGAB|NBROPERATIONGAB|HasCreditYousr|ALREADY CONNECTED|ACTIVE_RATIO|CONNECTED RECENTLY|Churn_next_trim|\n",
            "+--------+----------+--------+--------------+---+---+--------------+---------+--------+-------+-------+--------+--------+--------------+---------------+-----------------+------------+----------+---------------+--------------+-----------------+------------+------------------+---------------+\n",
            "|       0|2019-04-01| Féminin|      Marié(e)|  1| 64|            23|    55-64| 1025.33|3452.73|   9.33|  2500.0|     1.0|           0.0|            0.0|          1616.67|        1.33|   2133.33|           7.33|             0|                0|         1.0|                 0|              0|\n",
            "|       2|2019-04-01| Féminin|      Marié(e)|  1| 70|            45|      65+| 5757.81| 7097.8|   2.67| 4100.77|     2.0|           0.0|            0.0|           1800.0|        1.67|   2666.67|           3.33|             0|                0|         1.0|                 0|              0|\n",
            "|       3|2019-07-01| Féminin|   Celibataire|  1| 51|            17|    45-54| -881.56|  18.33|    0.0|     0.0|     0.0|           0.0|            0.0|              0.0|         0.0|       0.0|            0.0|             0|                0|         1.0|                 0|              0|\n",
            "|       4|2019-04-01|Masculin|      Marié(e)|  1| 50|             6|    45-54|  236.91| 208.81|   3.67|   600.0|     1.0|           0.0|            0.0|              0.0|         0.0|     200.0|           0.67|             0|                0|         1.0|                 0|              0|\n",
            "|       4|2020-01-01|Masculin|      Marié(e)|  1| 50|             6|    45-54|  143.16| 1013.2|   5.33|  1000.0|     1.0|           0.0|            0.0|              0.0|         0.0|       0.0|            0.0|             0|                0|         1.0|                 0|              0|\n",
            "|       5|2019-04-01| Féminin|      Marié(e)|  1| 41|             9|    35-44| 4211.08|    0.0|    0.0|     0.0|     0.0|           0.0|            0.0|              0.0|         0.0|    3700.0|            3.0|             1|                1|     0.10896|                 0|              0|\n",
            "|       7|2019-07-01| Féminin|   Celibataire|  1| 34|            12|    25-34| 5734.74|5293.04|    0.0|     0.0|     0.0|           0.0|            0.0|              0.0|         0.0|   1933.33|           2.33|             0|                0|         1.0|                 0|              0|\n",
            "|       9|2019-04-01|Masculin|   Celibataire|  1| 39|             3|    35-44| 1006.83| 1545.0|    0.0|     0.0|     0.0|           0.0|            0.0|           533.33|        0.33|    866.67|           2.67|             0|                0|         1.0|                 0|              0|\n",
            "|      13|2020-01-01|Masculin|   Celibataire|  1| 37|             6|    35-44| -777.28|  38.01|   1.33|     0.0|     0.0|           0.0|            0.0|              0.0|         0.0|       0.0|            0.0|             0|                0|         1.0|                 0|              0|\n",
            "|      14|2019-10-01| Féminin|      Marié(e)|  1| 35|             4|    35-44| 2904.98|1047.07|   3.33| 2466.67|    1.33|           0.0|            0.0|              0.0|         0.0|   1833.33|           2.67|             0|                0|         1.0|                 0|              0|\n",
            "|      16|2019-10-01| Féminin|   Celibataire|  1| 25|             7|    25-34|  535.23| 782.15|    0.0|     0.0|     0.0|           0.0|            0.0|              0.0|         0.0|       0.0|            0.0|             0|                0|         1.0|                 0|              0|\n",
            "|      17|2020-01-01| Féminin|   Celibataire|  1| 26|             7|    25-34| 1646.97|  12.67|   0.67|  1600.0|     1.0|           0.0|            0.0|           2400.0|        1.33|   1366.67|           5.33|             0|                0|         1.0|                 0|              0|\n",
            "|      21|2019-07-01|Masculin|      Marié(e)|  1| 43|             6|    35-44|   82.63|   11.0|   1.33|     0.0|     0.0|           0.0|            0.0|              0.0|         0.0|       0.0|            0.0|             0|                0|         1.0|                 0|              0|\n",
            "|      22|2019-10-01|Masculin|   Celibataire|  1| 26|             3|    25-34| 3684.81|2776.67|   15.0| 5035.35|    4.67|           0.0|            0.0|              0.0|         0.0|       0.0|            0.0|             0|                0|         1.0|                 0|              0|\n",
            "|      25|2019-10-01|Masculin|      Marié(e)|  1| 65|            24|      65+|     0.0|7684.21|    0.0|     0.0|     0.0|           0.0|            0.0|              0.0|         0.0|       0.0|            0.0|             0|                0|         1.0|                 0|              0|\n",
            "|      27|2019-04-01|Masculin|      Marié(e)|  1| 70|             2|      65+|  453.39|3006.47|   4.33| 3041.79|    1.33|           0.0|            0.0|           1000.0|        0.33|       0.0|            0.0|             0|                0|         1.0|                 0|              0|\n",
            "|      29|2019-10-01| Féminin|     Veuf (ve)|  1| 54|             9|    45-54|  784.07|  516.5|   2.67|  760.66|     1.0|           0.0|            0.0|              0.0|         0.0|    733.33|           1.33|             0|                0|         1.0|                 0|              0|\n",
            "|      34|2019-04-01|Masculin|      Marié(e)|  1| 75|            23|      65+|   87.82|2449.27|   13.0| 2250.75|    3.33|           0.0|            0.0|          -183.33|        0.67|    166.67|            0.0|             0|                0|         1.0|                 0|              0|\n",
            "|      36|2020-01-01| Féminin|   Celibataire|  1| 36|             4|    35-44|44903.94|   16.5|   1.33| 1211.88|    1.33|           0.0|            0.0|              0.0|         0.0|       0.0|            0.0|             0|                0|         1.0|                 0|              0|\n",
            "|      38|2019-07-01|Masculin|   Celibataire|  1| 54|            22|    45-54|157585.4|    0.0|  11.67|20293.18|     3.0|           0.0|            0.0|        -32166.67|        0.67|    7500.0|           5.67|             0|                1|     0.20935|                 1|              0|\n",
            "+--------+----------+--------+--------------+---+---+--------------+---------+--------+-------+-------+--------+--------+--------------+---------------+-----------------+------------+----------+---------------+--------------+-----------------+------------+------------------+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "master.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import col, when\n",
        "\n",
        "\n",
        "categorical_columns = [\"genre\", \"MARITAL_STATUS\", \"BPR\", \"AGE_GROUP\", \"HasCreditYousr\", \"ALREADY CONNECTED\", \"CONNECTED RECENTLY\"]\n",
        "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\") for column in categorical_columns]\n",
        "\n",
        "\n",
        "\n",
        "encoders = [OneHotEncoder(inputCol=column+\"_index\", outputCol=column+\"_ohe\") for column in categorical_columns]\n",
        "\n",
        "num_features = ['age', 'CUSTOMER_YEARS', 'SOLDE', 'MVTDEB', 'NBMVTDB', 'MVTCRED', 'NBMVTCRE', 'MONTANTFACTURE',\n",
        "                'MONTANTVIREMENT', 'MONTANTOPERATIONS', 'NBROPERATION', 'MONTANTGAB', 'NBROPERATIONGAB', 'ACTIVE_RATIO']\n",
        "\n",
        "\n",
        "encoded_features = [column+\"_ohe\" for column in categorical_columns]\n",
        "\n",
        "assembler = VectorAssembler(inputCols=num_features + encoded_features, outputCol='features')\n",
        "\n",
        "\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=True, withMean=False)\n",
        "\n",
        "\n",
        "pipeline = Pipeline(stages=indexers + encoders + [assembler, scaler])\n",
        "\n",
        "\n",
        "train, test = master.randomSplit([0.7, 0.3], seed=123)\n"
      ],
      "metadata": {
        "id": "Nc4FCe7hBoJJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = master.randomSplit([0.7, 0.3], seed=123)\n",
        "\n",
        "pipeline_model = pipeline.fit(train)\n",
        "\n",
        "train_transformed = pipeline_model.transform(train).withColumn(\"label\", col(\"Churn_next_trim\")).select(\"scaledFeatures\", \"label\")\n",
        "test_transformed = pipeline_model.transform(test).withColumn(\"label\", col(\"Churn_next_trim\")).select(\"scaledFeatures\", \"label\")\n",
        "\n",
        "train_transformed.show(5)\n"
      ],
      "metadata": {
        "id": "nvhNAGnABqaA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da1803cc-6192-4cee-edfd-d024e856aa53"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|      scaledFeatures|label|\n",
            "+--------------------+-----+\n",
            "|(41,[0,1,2,3,4,5,...|    0|\n",
            "|(41,[0,1,2,3,9,10...|    0|\n",
            "|(41,[0,1,2,3,4,13...|    0|\n",
            "|(41,[0,1,3,4,9,10...|    0|\n",
            "|(41,[0,1,2,13,15,...|    0|\n",
            "+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, DecisionTreeClassifier, GBTClassifier, MultilayerPerceptronClassifier\n",
        "\n",
        "# Initialize evaluators\n",
        "binary_evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
        "multi_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
        "\n",
        "# Function to evaluate model metrics\n",
        "def evaluate_model(predictions):\n",
        "    # Calculate AUC\n",
        "    auc = binary_evaluator.evaluate(predictions)\n",
        "\n",
        "    # Calculate Accuracy\n",
        "    accuracy = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"accuracy\"})\n",
        "\n",
        "    # Calculate Recall\n",
        "    recall = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"weightedRecall\"})\n",
        "\n",
        "    # Calculate F1-Score\n",
        "    f1_score = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"f1\"})\n",
        "\n",
        "    # Calculate Precision\n",
        "    precision = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"weightedPrecision\"})\n",
        "\n",
        "    # Return metrics as a dictionary\n",
        "    return {\n",
        "        \"AUC\": auc,\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Recall\": recall,\n",
        "        \"F1-Score\": f1_score,\n",
        "        \"Precision\": precision\n",
        "    }\n",
        "\n",
        "# Define the models to train and evaluate\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(labelCol=\"label\", featuresCol=\"scaledFeatures\", maxIter=100),\n",
        "    \"Random Forest\": RandomForestClassifier(labelCol=\"label\", featuresCol=\"scaledFeatures\"),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"scaledFeatures\"),\n",
        "    \"Gradient Boosting\": GBTClassifier(labelCol=\"label\", featuresCol=\"scaledFeatures\", maxIter=100),\n",
        "    \"Multilayer Perceptron\": MultilayerPerceptronClassifier(labelCol=\"label\", featuresCol=\"scaledFeatures\", layers=[train_transformed.select(\"scaledFeatures\").first()[\"scaledFeatures\"].size, 5, 4, 2], maxIter=100)\n",
        "}\n",
        "\n",
        "# Dictionary to store results\n",
        "metrics_results = []\n",
        "\n",
        "# Fit models and evaluate\n",
        "for model_name, model in models.items():\n",
        "    print(f\"Training and evaluating {model_name}...\")\n",
        "    model_trained = model.fit(train_transformed)\n",
        "    predictions = model_trained.transform(test_transformed)\n",
        "\n",
        "    # Evaluate the model\n",
        "    metrics = evaluate_model(predictions)\n",
        "\n",
        "    # Append results for this model\n",
        "    metrics_results.append((model_name, metrics[\"AUC\"], metrics[\"Accuracy\"], metrics[\"Precision\"], metrics[\"Recall\"], metrics[\"F1-Score\"]))\n",
        "\n",
        "# Convert the metrics results to DataFrame\n",
        "metrics_df = spark.createDataFrame(metrics_results, [\"Model\", \"AUC\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"])\n",
        "# Show metrics\n",
        "metrics_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4VDDd7u5v6W",
        "outputId": "9dda63ef-be75-4afe-f8d4-16da3d06bcce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and evaluating Logistic Regression...\n",
            "Training and evaluating Random Forest...\n",
            "Training and evaluating Decision Tree...\n",
            "Training and evaluating Gradient Boosting...\n",
            "Training and evaluating Multilayer Perceptron...\n",
            "+---------------------+------------------+-----------------+------------------+-----------------+------------------+\n",
            "|Model                |AUC               |Accuracy         |Precision         |Recall           |F1-Score          |\n",
            "+---------------------+------------------+-----------------+------------------+-----------------+------------------+\n",
            "|Logistic Regression  |0.6160642674446796|0.998948632337711|0.9978983700493834|0.998948632337711|0.9984232249954026|\n",
            "|Random Forest        |0.5793408921002605|0.998948632337711|0.9978983700493834|0.998948632337711|0.9984232249954026|\n",
            "|Decision Tree        |0.5               |0.998948632337711|0.9978983700493834|0.998948632337711|0.9984232249954026|\n",
            "|Gradient Boosting    |0.6624898847935579|0.998948632337711|0.9978983700493834|0.998948632337711|0.9984232249954026|\n",
            "|Multilayer Perceptron|0.6187449212535292|0.998948632337711|0.9978983700493834|0.998948632337711|0.9984232249954026|\n",
            "+---------------------+------------------+-----------------+------------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Balancing using SMOTE"
      ],
      "metadata": {
        "id": "cQ2xj37nRP-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SmoteConfig:\n",
        "    def __init__(self, k, bucketLength, seed, multiplier):\n",
        "        self.k = k\n",
        "        self.bucketLength = bucketLength\n",
        "        self.seed = seed\n",
        "        self.multiplier = multiplier\n",
        "\n",
        "# Initialize the SMOTE configuration\n",
        "smote_config = SmoteConfig(k=5, bucketLength=2.0, seed=42, multiplier=500)\n"
      ],
      "metadata": {
        "id": "S1eDop1wf5aB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imbalanced-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5cGEbsNm3dZ",
        "outputId": "0d904d50-11a2-4c55-e194-00f610e8ac65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting imbalanced-learn\n",
            "  Downloading imbalanced_learn-0.12.4-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.5.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n",
            "Downloading imbalanced_learn-0.12.4-py3-none-any.whl (258 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.3/258.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: imbalanced-learn\n",
            "Successfully installed imbalanced-learn-0.12.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming your data is in a Spark DataFrame with 'scaledFeatures' and 'label' columns\n",
        "train_pd = train_transformed.toPandas()  # Convert Spark DataFrame to Pandas DataFrame for SMOTE\n",
        "\n",
        "# Separate features and labels\n",
        "X_train = np.array(train_pd['scaledFeatures'].tolist())  # Convert the scaled features to an array\n",
        "y_train = train_pd['label'].values\n",
        "\n",
        "# Apply SMOTE using the configuration\n",
        "smote = SMOTE(sampling_strategy='auto', k_neighbors=smote_config.k, random_state=smote_config.seed)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Convert the resampled data back to a Spark DataFrame\n",
        "train_resampled = pd.DataFrame(X_resampled, columns=[f\"feature_{i}\" for i in range(X_resampled.shape[1])])\n",
        "train_resampled['label'] = y_resampled\n",
        "\n",
        "train_resampled_spark = spark.createDataFrame(train_resampled)\n",
        "\n",
        "# Now you have the resampled training set, you can use it for further modeling\n",
        "train_resampled_spark.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVExb7-whlCo",
        "outputId": "ba8c88f8-44c6-412c-818a-d3ea205442dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+------------------+--------------------+--------------------+--------------------+--------------------+------------------+---------+---------+-------------------+-------------------+-------------------+------------------+------------------+------------------+-----------------+------------------+----------+----------+----------+----------+----------+----------+-----------------+------------------+----------+----------+----------+----------+----------+----------+----------+------------------+----------+----------+-----------------+------------------+----------+-----------------+-----------------+------------------+-----+\n",
            "|        feature_0|         feature_1|           feature_2|           feature_3|           feature_4|           feature_5|         feature_6|feature_7|feature_8|          feature_9|         feature_10|         feature_11|        feature_12|        feature_13|        feature_14|       feature_15|        feature_16|feature_17|feature_18|feature_19|feature_20|feature_21|feature_22|       feature_23|        feature_24|feature_25|feature_26|feature_27|feature_28|feature_29|feature_30|feature_31|        feature_32|feature_33|feature_34|       feature_35|        feature_36|feature_37|       feature_38|       feature_39|        feature_40|label|\n",
            "+-----------------+------------------+--------------------+--------------------+--------------------+--------------------+------------------+---------+---------+-------------------+-------------------+-------------------+------------------+------------------+------------------+-----------------+------------------+----------+----------+----------+----------+----------+----------+-----------------+------------------+----------+----------+----------+----------+----------+----------+----------+------------------+----------+----------+-----------------+------------------+----------+-----------------+-----------------+------------------+-----+\n",
            "|4.148243775950587|2.6664682125355044|0.005527121433448422| 0.04284975711177755|  1.6932248056295847|0.028579473886329244|0.3576429488241454|      0.0|      0.0|0.04359258463845932|0.43931924593088145|0.10156344922632883|1.5731428124033555|12.421187476489171|               0.0|2.000677632363292|               0.0|       0.0|       0.0|       0.0|       0.0|       0.0|       0.0|              0.0|3.4382620856903703|       0.0|       0.0|       0.0|       0.0|       0.0|       0.0|       0.0|               0.0|       0.0|       0.0|2.758699261169388|               0.0|       0.0|4.782291284286356|9.017181196294809|17.972411913281604|    0|\n",
            "|2.463019741970661|1.2752674059952411|-0.00725711966000...|1.324189578631014...| 0.18148175837401764|                 0.0|               0.0|      0.0|      0.0|                0.0|                0.0|                0.0|               0.0|12.421187476489171|               0.0|              0.0|2.0615144342469454|       0.0|       0.0|       0.0|       0.0|       0.0|       0.0|              0.0|3.4382620856903703|       0.0|       0.0|       0.0|       0.0|       0.0|       0.0|       0.0|2.3499217839661903|       0.0|       0.0|              0.0|               0.0|       0.0|4.782291284286356|9.017181196294809|17.972411913281604|    0|\n",
            "|5.379753646935918| 4.985136223435942|-0.00210938711256...|                 0.0|                 0.0|                 0.0|               0.0|      0.0|      0.0|                0.0|                0.0|                0.0|               0.0|12.421187476489171|2.1595573000370947|2.000677632363292|               0.0|       0.0|       0.0|       0.0|       0.0|       0.0|       0.0|3.287299695740792|               0.0|       0.0|       0.0|       0.0|       0.0|       0.0|       0.0|       0.0|               0.0|       0.0|       0.0|              0.0|3.0856460578908127|       0.0|4.782291284286356|9.017181196294809|17.972411913281604|    0|\n",
            "|5.120488410939006|  4.86920282289092|-0.00729560838757...|2.010484646093949...|0.059888980263425824|                 0.0|               0.0|      0.0|      0.0|                0.0|                0.0|                0.0|               0.0|12.421187476489171|2.1595573000370947|2.000677632363292|               0.0|       0.0|       0.0|       0.0|       0.0|       0.0|       0.0|3.287299695740792|               0.0|       0.0|       0.0|       0.0|       0.0|       0.0|       0.0|       0.0|               0.0|       0.0|       0.0|              0.0|3.0856460578908127|       0.0|4.782291284286356|9.017181196294809|17.972411913281604|    0|\n",
            "| 4.08342746695136|3.3620686158056357|-0.00112911048681...|0.024513888931419727|   1.573446845102733|0.022863579109063396|0.2396207757121774|      0.0|      0.0|                0.0|                0.0|0.09521588242449958|1.5023191932910627|12.421187476489171|2.1595573000370947|2.000677632363292|               0.0|       0.0|       0.0|       0.0|       0.0|       0.0|       0.0|3.287299695740792|               0.0|       0.0|       0.0|       0.0|       0.0|       0.0|       0.0|       0.0|               0.0|       0.0|       0.0|2.758699261169388|               0.0|       0.0|4.782291284286356|9.017181196294809|17.972411913281604|    0|\n",
            "+-----------------+------------------+--------------------+--------------------+--------------------+--------------------+------------------+---------+---------+-------------------+-------------------+-------------------+------------------+------------------+------------------+-----------------+------------------+----------+----------+----------+----------+----------+----------+-----------------+------------------+----------+----------+----------+----------+----------+----------+----------+------------------+----------+----------+-----------------+------------------+----------+-----------------+-----------------+------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, DecisionTreeClassifier, GBTClassifier, MultilayerPerceptronClassifier\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.linalg import Vectors, VectorUDT\n",
        "\n",
        "\n",
        "# Assuming 'scaledFeatures' is a vector in Spark\n",
        "# Convert resampled pandas data back to a Spark DataFrame with correct vector type for 'scaledFeatures'\n",
        "train_resampled_spark = train_resampled_spark.withColumn(\n",
        "    'scaledFeatures', F.udf(lambda x: Vectors.dense(x), VectorUDT())(F.array([F.col(f\"feature_{i}\") for i in range(X_resampled.shape[1])]))\n",
        ")\n",
        "\n",
        "# Extract the input size for the MLP layers\n",
        "input_size = len(train_resampled_spark.select(\"scaledFeatures\").first()[\"scaledFeatures\"])\n",
        "\n",
        "mlp_layers = [input_size, 5, 4, 2]  # Define the MLP architecture\n",
        "\n",
        "# Define evaluators\n",
        "binary_evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
        "multi_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
        "\n",
        "# Function to evaluate model metrics\n",
        "def evaluate_model(predictions):\n",
        "    auc = binary_evaluator.evaluate(predictions)\n",
        "    accuracy = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"accuracy\"})\n",
        "    recall = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"weightedRecall\"})\n",
        "    f1_score = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"f1\"})\n",
        "    precision = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"weightedPrecision\"})\n",
        "    return {\n",
        "        \"AUC\": auc,\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Recall\": recall,\n",
        "        \"F1-Score\": f1_score,\n",
        "        \"Precision\": precision\n",
        "    }\n",
        "\n",
        "# Define the models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(labelCol=\"label\", featuresCol=\"scaledFeatures\", maxIter=100),\n",
        "    \"Random Forest\": RandomForestClassifier(labelCol=\"label\", featuresCol=\"scaledFeatures\"),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"scaledFeatures\"),\n",
        "    \"Gradient Boosting\": GBTClassifier(labelCol=\"label\", featuresCol=\"scaledFeatures\", maxIter=100),\n",
        "    \"Multilayer Perceptron\": MultilayerPerceptronClassifier(labelCol=\"label\", featuresCol=\"scaledFeatures\", layers=mlp_layers, maxIter=100)\n",
        "}\n",
        "\n",
        "# Store results\n",
        "metrics_results = []\n",
        "\n",
        "# Train models and evaluate\n",
        "for model_name, model in models.items():\n",
        "    print(f\"Training and evaluating {model_name}...\")\n",
        "    model_trained = model.fit(train_resampled_spark)  # Train on resampled data\n",
        "    predictions = model_trained.transform(test_transformed)  # Ensure test_transformed is prepared similarly to training data\n",
        "\n",
        "    metrics = evaluate_model(predictions)\n",
        "    metrics_results.append((model_name, metrics[\"AUC\"], metrics[\"Accuracy\"], metrics[\"Precision\"], metrics[\"Recall\"], metrics[\"F1-Score\"]))\n",
        "\n",
        "# Convert to DataFrame and display\n",
        "metrics_df = spark.createDataFrame(metrics_results, [\"Model\", \"AUC\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"])\n",
        "metrics_df.show(truncate=False)\n"
      ],
      "metadata": {
        "id": "hchLTKBhSPEE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23959022-d6f7-4f46-d62b-d30188457fe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and evaluating Logistic Regression...\n",
            "Training and evaluating Random Forest...\n",
            "Training and evaluating Decision Tree...\n",
            "Training and evaluating Gradient Boosting...\n",
            "Training and evaluating Multilayer Perceptron...\n",
            "+---------------------+------------------+------------------+------------------+------------------+------------------+\n",
            "|Model                |AUC               |Accuracy          |Precision         |Recall            |F1-Score          |\n",
            "+---------------------+------------------+------------------+------------------+------------------+------------------+\n",
            "|Logistic Regression  |0.6226531682277188|0.5581032934337667|0.9982182216659893|0.5581032934337669|0.7154040278332193|\n",
            "|Random Forest        |0.5813250325670396|0.6876376849473629|0.9980781817457444|0.6876376849473629|0.8139588875856224|\n",
            "|Decision Tree        |0.5543239554379721|0.6370511790056617|0.9980380139049291|0.6370511790056618|0.777348383462843 |\n",
            "|Gradient Boosting    |0.610744975141238 |0.9819056677560277|0.9979572985247719|0.9819056677560277|0.9898360762700503|\n",
            "|Multilayer Perceptron|0.6200206433497439|0.5503153120400266|0.9982560055919781|0.5503153120400267|0.7089462221403378|\n",
            "+---------------------+------------------+------------------+------------------+------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class_count = master.groupBy(\"Churn_next_trim\").count().collect()\n",
        "\n",
        "majority_count = -1\n",
        "minority_count = float('inf')\n",
        "\n",
        "for row in class_count:\n",
        "    count_value = row['count']\n",
        "    if count_value > majority_count:\n",
        "        majority_count = count_value\n",
        "    if count_value < minority_count:\n",
        "        minority_count = count_value\n",
        "\n",
        "\n",
        "print(\"Majority count:\", majority_count)\n",
        "print(\"Minority count:\", minority_count)\n",
        "train_weighted = train_transformed.withColumn(\"classWeightCol\", when(train_transformed[\"label\"] == 1, majority_count/minority_count).otherwise(1.0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPem9kwCBsxv",
        "outputId": "5af950a8-bca8-4c3b-f760-5c9efcd4d248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Majority count: 3388530\n",
            "Minority count: 3654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, DecisionTreeClassifier, GBTClassifier, MultilayerPerceptronClassifier\n",
        "\n",
        "# Initialize evaluators\n",
        "binary_evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
        "multi_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
        "\n",
        "# Function to evaluate model metrics\n",
        "def evaluate_model(predictions):\n",
        "    # Calculate AUC\n",
        "    auc = binary_evaluator.evaluate(predictions)\n",
        "\n",
        "    # Calculate Accuracy\n",
        "    accuracy = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"accuracy\"})\n",
        "\n",
        "    # Calculate Recall\n",
        "    recall = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"weightedRecall\"})\n",
        "\n",
        "    # Calculate F1-Score\n",
        "    f1_score = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"f1\"})\n",
        "\n",
        "    # Calculate Precision\n",
        "    precision = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"weightedPrecision\"})\n",
        "\n",
        "    # Return metrics as a dictionary\n",
        "    return {\n",
        "        \"AUC\": auc,\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Recall\": recall,\n",
        "        \"F1-Score\": f1_score,\n",
        "        \"Precision\": precision\n",
        "    }\n",
        "\n",
        "# Define the models to train and evaluate\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(labelCol=\"label\", featuresCol=\"scaledFeatures\", weightCol=\"classWeightCol\", maxIter=100),\n",
        "    \"Random Forest\": RandomForestClassifier(labelCol=\"label\", featuresCol=\"scaledFeatures\", weightCol=\"classWeightCol\"),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"scaledFeatures\"),\n",
        "    \"Gradient Boosting\": GBTClassifier(labelCol=\"label\", featuresCol=\"scaledFeatures\", maxIter=100),\n",
        "    \"Multilayer Perceptron\": MultilayerPerceptronClassifier(labelCol=\"label\", featuresCol=\"scaledFeatures\", layers=[train_weighted.select(\"scaledFeatures\").first()[\"scaledFeatures\"].size, 5, 4, 2], maxIter=100)\n",
        "}\n",
        "\n",
        "# Dictionary to store results\n",
        "metrics_results = []\n",
        "\n",
        "# Fit models and evaluate\n",
        "for model_name, model in models.items():\n",
        "    print(f\"Training and evaluating {model_name}...\")\n",
        "    model_trained = model.fit(train_weighted)\n",
        "    predictions = model_trained.transform(test_transformed)\n",
        "\n",
        "    # Evaluate the model\n",
        "    metrics = evaluate_model(predictions)\n",
        "\n",
        "    # Append results for this model\n",
        "    metrics_results.append((model_name, metrics[\"AUC\"], metrics[\"Accuracy\"], metrics[\"Precision\"], metrics[\"Recall\"], metrics[\"F1-Score\"]))\n",
        "\n",
        "# Convert the metrics results to DataFrame\n",
        "metrics_df = spark.createDataFrame(metrics_results, [\"Model\", \"AUC\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"])\n",
        "# Show metrics\n",
        "metrics_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z51tl9ARrq1Q",
        "outputId": "afa07d5e-ccd8-45c4-8e3b-24546d0e99c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and evaluating Logistic Regression...\n",
            "Training and evaluating Random Forest...\n",
            "Training and evaluating Decision Tree...\n",
            "Training and evaluating Gradient Boosting...\n",
            "Training and evaluating Multilayer Perceptron...\n",
            "+---------------------+------------------+------------------+------------------+------------------+------------------+\n",
            "|Model                |AUC               |Accuracy          |Precision         |Recall            |F1-Score          |\n",
            "+---------------------+------------------+------------------+------------------+------------------+------------------+\n",
            "|Logistic Regression  |0.622462166085117 |0.563697158949104 |0.9982167986648781|0.563697158949104 |0.719997487898472 |\n",
            "|Random Forest        |0.6512157625978561|0.5869294365258882|0.9983011440664163|0.5869294365258881|0.7387104280879194|\n",
            "|Decision Tree        |0.5               |0.998948632337711 |0.9978983700493834|0.998948632337711 |0.9984232249954026|\n",
            "|Gradient Boosting    |0.6624879120364328|0.998948632337711 |0.9978983700493834|0.998948632337711 |0.9984232249954026|\n",
            "|Multilayer Perceptron|0.6176029531935149|0.998948632337711 |0.9978983700493834|0.998948632337711 |0.9984232249954026|\n",
            "+---------------------+------------------+------------------+------------------+------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.ml.linalg import Vectors, VectorUDT\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, DecisionTreeClassifier, GBTClassifier, MultilayerPerceptronClassifier\n",
        "from imblearn.combine import SMOTETomek\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Convert Spark DataFrame to Pandas DataFrame for SMOTE-Tomek Link\n",
        "train_pd = train_transformed.toPandas()  # Convert Spark DataFrame to Pandas DataFrame\n",
        "\n",
        "# Separate features and labels\n",
        "X_train = np.array(train_pd['scaledFeatures'].tolist())  # Convert the 'scaledFeatures' vector to an array\n",
        "y_train = train_pd['label'].values  # Extract labels\n",
        "\n",
        "# Apply SMOTE-Tomek Link\n",
        "smote_tomek = SMOTETomek(sampling_strategy='auto', random_state=42)  # Use desired random_state\n",
        "X_resampled, y_resampled = smote_tomek.fit_resample(X_train, y_train)\n",
        "\n",
        "# Convert resampled data back to Pandas DataFrame\n",
        "train_resampled = pd.DataFrame(X_resampled, columns=[f\"feature_{i}\" for i in range(X_resampled.shape[1])])\n",
        "train_resampled['label'] = y_resampled\n",
        "\n",
        "# Convert back to Spark DataFrame and create vector column for 'scaledFeatures'\n",
        "train_resampled_spark = spark.createDataFrame(train_resampled)\n",
        "\n",
        "# Recreate 'scaledFeatures' as a vector column in Spark DataFrame\n",
        "train_resampled_spark = train_resampled_spark.withColumn(\n",
        "    'scaledFeatures', F.udf(lambda x: Vectors.dense(x), VectorUDT())(F.array([F.col(f\"feature_{i}\") for i in range(X_resampled.shape[1])]))\n",
        ")\n",
        "\n",
        "# Extract the input size for MLP layers\n",
        "input_size = len(train_resampled_spark.select(\"scaledFeatures\").first()[\"scaledFeatures\"])\n",
        "\n",
        "# Define the MLP architecture\n",
        "mlp_layers = [input_size, 5, 4, 2]  # Example MLP architecture\n",
        "\n",
        "# Define evaluators\n",
        "binary_evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
        "multi_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
        "\n",
        "# Function to evaluate model metrics\n",
        "def evaluate_model(predictions):\n",
        "    auc = binary_evaluator.evaluate(predictions)\n",
        "    accuracy = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"accuracy\"})\n",
        "    recall = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"weightedRecall\"})\n",
        "    f1_score = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"f1\"})\n",
        "    precision = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"weightedPrecision\"})\n",
        "    return {\n",
        "        \"AUC\": auc,\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Recall\": recall,\n",
        "        \"F1-Score\": f1_score,\n",
        "        \"Precision\": precision\n",
        "    }\n",
        "\n",
        "# Define the models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(labelCol=\"label\", featuresCol=\"scaledFeatures\", maxIter=100),\n",
        "    \"Random Forest\": RandomForestClassifier(labelCol=\"label\", featuresCol=\"scaledFeatures\"),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"scaledFeatures\"),\n",
        "    \"Gradient Boosting\": GBTClassifier(labelCol=\"label\", featuresCol=\"scaledFeatures\", maxIter=100),\n",
        "    \"Multilayer Perceptron\": MultilayerPerceptronClassifier(labelCol=\"label\", featuresCol=\"scaledFeatures\", layers=mlp_layers, maxIter=100)\n",
        "}\n",
        "\n",
        "# Store results\n",
        "metrics_results = []\n",
        "\n",
        "# Train models and evaluate\n",
        "for model_name, model in models.items():\n",
        "    print(f\"Training and evaluating {model_name}...\")\n",
        "    model_trained = model.fit(train_resampled_spark)  # Train on resampled data\n",
        "    predictions = model_trained.transform(test_transformed)  # Ensure test_transformed is prepared similarly to training data\n",
        "\n",
        "    metrics = evaluate_model(predictions)\n",
        "    metrics_results.append((model_name, metrics[\"AUC\"], metrics[\"Accuracy\"], metrics[\"Precision\"], metrics[\"Recall\"], metrics[\"F1-Score\"]))\n",
        "\n",
        "# Convert to DataFrame and display\n",
        "metrics_df = spark.createDataFrame(metrics_results, [\"Model\", \"AUC\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"])\n",
        "metrics_df.show(truncate=False)\n"
      ],
      "metadata": {
        "id": "z9EQpL7k5rTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.ml.linalg import Vectors, VectorUDT\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, DecisionTreeClassifier, GBTClassifier, MultilayerPerceptronClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Convert Spark DataFrame to Pandas DataFrame for SMOTE + Random Undersampling\n",
        "train_pd = train_transformed.toPandas()  # Convert Spark DataFrame to Pandas\n",
        "\n",
        "# Separate features and labels\n",
        "X_train = np.array(train_pd['scaledFeatures'].tolist())  # Convert 'scaledFeatures' vector to an array\n",
        "y_train = train_pd['label'].values  # Extract labels\n",
        "\n",
        "# Step 2: Apply SMOTE for oversampling the minority class\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_smote_resampled, y_smote_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Step 3: Apply Random Undersampling to the majority class\n",
        "undersampler = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
        "X_resampled, y_resampled = undersampler.fit_resample(X_smote_resampled, y_smote_resampled)\n",
        "\n",
        "# Step 4: Convert resampled data back to a Pandas DataFrame\n",
        "train_resampled = pd.DataFrame(X_resampled, columns=[f\"feature_{i}\" for i in range(X_resampled.shape[1])])\n",
        "train_resampled['label'] = y_resampled\n",
        "\n",
        "# Step 5: Convert back to Spark DataFrame and create vector column for 'scaledFeatures'\n",
        "train_resampled_spark = spark.createDataFrame(train_resampled)\n",
        "\n",
        "# Recreate 'scaledFeatures' as a vector column in Spark DataFrame\n",
        "train_resampled_spark = train_resampled_spark.withColumn(\n",
        "    'scaledFeatures', F.udf(lambda x: Vectors.dense(x), VectorUDT())(F.array([F.col(f\"feature_{i}\") for i in range(X_resampled.shape[1])]))\n",
        ")\n",
        "\n",
        "# Extract the input size for MLP layers\n",
        "input_size = len(train_resampled_spark.select(\"scaledFeatures\").first()[\"scaledFeatures\"])\n",
        "\n",
        "# Define the MLP architecture\n",
        "mlp_layers = [input_size, 5, 4, 2]  # Example MLP architecture\n",
        "\n",
        "# Define evaluators\n",
        "binary_evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
        "multi_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
        "\n",
        "# Function to evaluate model metrics\n",
        "def evaluate_model(predictions):\n",
        "    auc = binary_evaluator.evaluate(predictions)\n",
        "    accuracy = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"accuracy\"})\n",
        "    recall = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"weightedRecall\"})\n",
        "    f1_score = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"f1\"})\n",
        "    precision = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"weightedPrecision\"})\n",
        "    return {\n",
        "        \"AUC\": auc,\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Recall\": recall,\n",
        "        \"F1-Score\": f1_score,\n",
        "        \"Precision\": precision\n",
        "    }\n",
        "\n",
        "# Define the models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(labelCol=\"label\", featuresCol=\"scaledFeatures\", maxIter=100),\n",
        "    \"Random Forest\": RandomForestClassifier(labelCol=\"label\", featuresCol=\"scaledFeatures\"),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"scaledFeatures\"),\n",
        "    \"Gradient Boosting\": GBTClassifier(labelCol=\"label\", featuresCol=\"scaledFeatures\", maxIter=100),\n",
        "    \"Multilayer Perceptron\": MultilayerPerceptronClassifier(labelCol=\"label\", featuresCol=\"scaledFeatures\", layers=mlp_layers, maxIter=100)\n",
        "}\n",
        "\n",
        "# Store results\n",
        "metrics_results = []\n",
        "\n",
        "# Train models and evaluate\n",
        "for model_name, model in models.items():\n",
        "    print(f\"Training and evaluating {model_name}...\")\n",
        "    model_trained = model.fit(train_resampled_spark)  # Train on resampled data\n",
        "    predictions = model_trained.transform(test_transformed)  # Ensure test_transformed is prepared similarly to training data\n",
        "\n",
        "    metrics = evaluate_model(predictions)\n",
        "    metrics_results.append((model_name, metrics[\"AUC\"], metrics[\"Accuracy\"], metrics[\"Precision\"], metrics[\"Recall\"], metrics[\"F1-Score\"]))\n",
        "\n",
        "# Convert to DataFrame and display\n",
        "metrics_df = spark.createDataFrame(metrics_results, [\"Model\", \"AUC\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"])\n",
        "metrics_df.show(truncate=False)\n"
      ],
      "metadata": {
        "id": "VeavAUHTRPG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xf9KfvikRPbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"scaledFeatures\", weightCol=\"classWeightCol\", maxIter=100)\n",
        "lr_model = lr.fit(train_weighted)\n",
        "lr_predictions = lr_model.transform(test_transformed)\n"
      ],
      "metadata": {
        "id": "IUFMdo4rB2zM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"scaledFeatures\", weightCol=\"classWeightCol\")\n",
        "rf_model = rf.fit(train_weighted)\n",
        "rf_predictions = rf_model.transform(test_transformed)\n"
      ],
      "metadata": {
        "id": "gz8g41mAB4SM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "\n",
        "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"scaledFeatures\")\n",
        "dt_model = dt.fit(train_weighted)\n",
        "dt_predictions = dt_model.transform(test_transformed)\n"
      ],
      "metadata": {
        "id": "WPJ-Iu6PB54t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import GBTClassifier\n",
        "\n",
        "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"scaledFeatures\", maxIter=100)\n",
        "gbt_model = gbt.fit(train_weighted)\n",
        "gbt_predictions = gbt_model.transform(test_transformed)\n"
      ],
      "metadata": {
        "id": "Y7BKyUAuB8IC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
        "\n",
        "layers = [train_weighted.select(\"scaledFeatures\").first()[\"scaledFeatures\"].size, 5, 4, 2]  # Adjust hidden layers as needed\n",
        "mlp = MultilayerPerceptronClassifier(labelCol=\"label\", featuresCol=\"scaledFeatures\", layers=layers, maxIter=100)\n",
        "mlp_model = mlp.fit(train_weighted)\n",
        "mlp_predictions = mlp_model.transform(test_transformed)\n"
      ],
      "metadata": {
        "id": "tyKWdP_gB-Fs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.sql.functions import expr\n",
        "\n",
        "# Helper function to calculate accuracy, precision, recall, and F1-score\n",
        "def calculate_metrics(predictions, label_col=\"label\"):\n",
        "    tp = predictions.filter((predictions[\"prediction\"] == 1) & (predictions[label_col] == 1)).count()\n",
        "    tn = predictions.filter((predictions[\"prediction\"] == 0) & (predictions[label_col] == 0)).count()\n",
        "    fp = predictions.filter((predictions[\"prediction\"] == 1) & (predictions[label_col] == 0)).count()\n",
        "    fn = predictions.filter((predictions[\"prediction\"] == 0) & (predictions[label_col] == 1)).count()\n",
        "\n",
        "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "    precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
        "    recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
        "    f1_score = 2 * ((precision * recall) / (precision + recall)) if precision + recall > 0 else 0\n",
        "\n",
        "    return accuracy, precision, recall, f1_score\n",
        "\n",
        "# Evaluate models and store metrics\n",
        "models = {\n",
        "    \"Logistic Regression\": lr_predictions,\n",
        "    \"Random Forest\": rf_predictions,\n",
        "    \"Decision Tree\": dt_predictions,\n",
        "    \"Gradient Boosting\": gbt_predictions,\n",
        "    \"MLP\": mlp_predictions\n",
        "}\n",
        "\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
        "metrics = []\n",
        "\n",
        "for model_name, predictions in models.items():\n",
        "    auc = evaluator.evaluate(predictions)\n",
        "    accuracy, precision, recall, f1_score = calculate_metrics(predictions)\n",
        "    metrics.append((model_name, auc, accuracy, precision, recall, f1_score))\n",
        "\n",
        "# Convert all metrics to float to avoid type mismatch\n",
        "metrics_float = [(model, float(auc), float(accuracy), float(precision), float(recall), float(f1_score))\n",
        "                 for model, auc, accuracy, precision, recall, f1_score in metrics]\n",
        "\n",
        "# Create a DataFrame to show the results in a table\n",
        "metrics_df = spark.createDataFrame(metrics_float, [\"Model\", \"AUC\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"])\n",
        "metrics_df.show(truncate=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99piwACcB-12",
        "outputId": "c3024c54-e406-4015-8fe8-af183933ac06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+------------------+------------------+---------------------+------------------+---------------------+\n",
            "|Model              |AUC               |Accuracy          |Precision            |Recall            |F1-Score             |\n",
            "+-------------------+------------------+------------------+---------------------+------------------+---------------------+\n",
            "|Logistic Regression|0.6175871369802802|0.5836405046306196|0.0015189265310543941|0.5687830687830688|0.003029762128443125 |\n",
            "|Random Forest      |0.6582918068964428|0.6363507069026736|0.0018061587316991641|0.5908289241622575|0.0036013082961780444|\n",
            "|Decision Tree      |0.5               |0.9988877096824186|0.0                  |0.0               |0.0                  |\n",
            "|Gradient Boosting  |0.6737377473168198|0.9988877096824186|0.0                  |0.0               |0.0                  |\n",
            "|MLP                |0.6257362002622799|0.9988877096824186|0.0                  |0.0               |0.0                  |\n",
            "+-------------------+------------------+------------------+---------------------+------------------+---------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import col, when\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "categorical_columns = [\"genre\", \"MARITAL_STATUS\", \"BPR\", \"AGE_GROUP\", \"HasCreditYousr\", \"ALREADY CONNECTED\", \"CONNECTED RECENTLY\"]\n",
        "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(master) for column in categorical_columns]\n",
        "encoders = [OneHotEncoder(inputCol=column+\"_index\", outputCol=column+\"_ohe\") for column in categorical_columns]\n",
        "\n",
        "num_features = ['age', 'CUSTOMER_YEARS', 'SOLDE', 'MVTDEB', 'NBMVTDB', 'MVTCRED', 'NBMVTCRE', 'MONTANTFACTURE',\n",
        "                'MONTANTVIREMENT', 'MONTANTOPERATIONS', 'NBROPERATION', 'MONTANTGAB', 'NBROPERATIONGAB', 'ACTIVE_RATIO']\n",
        "\n",
        "encoded_features = [column+\"_ohe\" for column in categorical_columns]\n",
        "assembler = VectorAssembler(inputCols=num_features + encoded_features, outputCol='features')\n",
        "\n",
        "# Optional: StandardScaler to normalize features\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=True, withMean=False)\n",
        "\n",
        "pipeline = Pipeline(stages=indexers + encoders + [assembler, scaler])\n",
        "\n",
        "train, test = master.randomSplit([0.7, 0.3], seed=123)\n",
        "\n",
        "# Fit the pipeline on the training set\n",
        "pipeline_model = pipeline.fit(train)\n",
        "\n",
        "# Transform both train and test sets\n",
        "train = pipeline_model.transform(train).withColumn(\"label\", col(\"Churn_next_trim\")).select(\"scaledFeatures\", \"label\")\n",
        "test = pipeline_model.transform(test).withColumn(\"label\", col(\"Churn_next_trim\")).select(\"scaledFeatures\", \"label\")\n",
        "\n",
        "class_count = master.groupBy(\"Churn_next_trim\").count().collect()\n",
        "\n",
        "majority_count = -1\n",
        "minority_count = float('inf')\n",
        "\n",
        "for row in class_count:\n",
        "    count_value = row['count']\n",
        "    if count_value > majority_count:\n",
        "        majority_count = count_value\n",
        "    if count_value < minority_count:\n",
        "        minority_count = count_value\n",
        "\n",
        "\n",
        "print(\"Majority count:\", majority_count)\n",
        "print(\"Minority count:\", minority_count)\n",
        "\n",
        "\n",
        "train_weighted = train.withColumn(\"classWeightCol\", when(train[\"label\"] == 1, majority_count/minority_count).otherwise(1.0))\n",
        "\n",
        "# Logistic Regression with class weights\n",
        "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"scaledFeatures\", weightCol=\"classWeightCol\", maxIter=100)\n",
        "lr_model = lr.fit(train_weighted)\n",
        "\n",
        "# Evaluate on test set\n",
        "predictions = lr_model.transform(test)\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
        "auc = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"AUC (Area Under ROC): {auc}\")\n"
      ],
      "metadata": {
        "id": "cikmzxha3vVs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1d94d77-6abb-416c-e035-ad6af45f8487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Majority count: 3388530\n",
            "Minority count: 3654\n",
            "AUC (Area Under ROC): 0.617587086757197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "# Utiliser MulticlassClassificationEvaluator pour d'autres métriques\n",
        "multi_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
        "\n",
        "# Calculer la précision\n",
        "accuracy = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"accuracy\"})\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
        "\n",
        "# Calculer le rappel\n",
        "recall = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"weightedRecall\"})\n",
        "print(\"Recall: {:.2f}%\".format(recall * 100))\n",
        "\n",
        "# Calculer le F1-score\n",
        "f1_score = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"f1\"})\n",
        "print(\"F1 Score: {:.2f}%\".format(f1_score * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TEhktbc_UaM",
        "outputId": "7299069b-b730-495e-b359-68463e2226bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 58.36%\n",
            "Recall: 58.36%\n",
            "F1 Score: 73.61%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiTgCvhVkBMQ"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml. feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "categorical_columns = [\"genre\", \"MARITAL_STATUS\", \"BPR\", \"AGE_GROUP\", \"HasCreditYousr\", \"ALREADY CONNECTED\",\n",
        "\"CONNECTED RECENTLY\"]\n",
        "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(master) for column in categorical_columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evjFYOiYtqfK"
      },
      "outputs": [],
      "source": [
        "encoders = [OneHotEncoder(inputCol=column+\"_index\", outputCol=column+\"_ohe\") for column in categorical_columns]\n",
        "\n",
        "num_features = ['age', 'CUSTOMER_YEARS', 'SOLDE', 'MVTDEB', 'NBMVTDB', 'MVTCRED', 'NBMVTCRE',\n",
        "'MONTANTFACTURE', 'MONTANTVIREMENT', 'MONTANTOPERATIONS', 'NBROPERATION', 'MONTANTGAB',\n",
        "'NBROPERATIONGAB', 'ACTIVE_RATIO' ]\n",
        "encoded_features = [column+\"_ohe\" for column in categorical_columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxzKLeQ1uCcu"
      },
      "outputs": [],
      "source": [
        "assembler = VectorAssembler(inputCols=num_features + encoded_features, outputCol='features')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9OfBLneufZU"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline(stages=indexers + encoders + [assembler])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Dr8ZU5Xmnb6"
      },
      "outputs": [],
      "source": [
        "train, test = master.randomSplit([0.7, 0.3], seed=123)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mI56icELraey",
        "outputId": "d033aa78-edce-40d2-e90f-c9df34c59015"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2372666"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLHmB6jnw4PC",
        "outputId": "7903cec1-df36-4573-ba29-be38a92fdf71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+--------+--------------+---+---+--------------+---------+---------+-------+-------+-------+--------+--------------+---------------+-----------------+------------+----------+---------------+--------------+-----------------+------------+------------------+---------------+\n",
            "|Idclient| ANNEEMOIS|   genre|MARITAL_STATUS|BPR|age|CUSTOMER_YEARS|AGE_GROUP|    SOLDE| MVTDEB|NBMVTDB|MVTCRED|NBMVTCRE|MONTANTFACTURE|MONTANTVIREMENT|MONTANTOPERATIONS|NBROPERATION|MONTANTGAB|NBROPERATIONGAB|HasCreditYousr|ALREADY CONNECTED|ACTIVE_RATIO|CONNECTED RECENTLY|Churn_next_trim|\n",
            "+--------+----------+--------+--------------+---+---+--------------+---------+---------+-------+-------+-------+--------+--------------+---------------+-----------------+------------+----------+---------------+--------------+-----------------+------------+------------------+---------------+\n",
            "|       0|2019-04-01| Féminin|      Marié(e)|  1| 64|            23|    55-64|  1025.33|3452.73|   9.33| 2500.0|     1.0|           0.0|            0.0|          1616.67|        1.33|   2133.33|           7.33|             0|                0|         1.0|                 0|              0|\n",
            "|      10|2019-07-01|Masculin|      Marié(e)|  1| 61|            12|    55-64|   246.33|6787.27|    0.0|    0.0|     0.0|           0.0|            0.0|           6600.0|        0.67|       0.0|            0.0|             0|                0|         1.0|                 0|              0|\n",
            "|     100|2019-10-01| Féminin|   Celibataire|  1| 38|            11|    35-44| -1346.26|  10.67|    1.0|    0.0|     0.0|           0.0|            0.0|              0.0|         0.0|       0.0|            0.0|             0|                0|         1.0|                 0|              0|\n",
            "|    1000|2019-04-01| Féminin|      Marié(e)| 27| 64|            28|    55-64|      0.0|36082.4|    1.0|    0.0|     0.0|           0.0|            0.0|          3266.67|        0.67|       0.0|            0.0|             0|                0|         1.0|                 0|              0|\n",
            "|    1000|2020-01-01| Féminin|      Marié(e)| 27| 64|            28|    55-64|   369.02|    0.0|    0.0|    0.0|     0.0|           0.0|            0.0|              0.0|         0.0|       0.0|            0.0|             0|                0|         1.0|                 0|              0|\n",
            "|  100001|2019-04-01|Masculin|   Celibataire| 90| 33|             6|    25-34| -3458.06|  14.67|    0.0|    0.0|     0.0|           0.0|            0.0|              0.0|         0.0|       0.0|            0.0|             0|                0|         1.0|                 0|              0|\n",
            "|  100001|2019-10-01|Masculin|   Celibataire| 90| 33|             6|    25-34| -3795.26|  14.67|    0.0|    0.0|     0.0|           0.0|            0.0|              0.0|         0.0|       0.0|            0.0|             0|                0|         1.0|                 0|              0|\n",
            "|  100002|2019-04-01| Féminin|      Marié(e)| 81| 28|             6|    25-34|   2626.3|    0.0|    0.0|    0.0|     0.0|           0.0|            0.0|              0.0|         0.0|       0.0|            0.0|             0|                0|         1.0|                 0|              0|\n",
            "|  100002|2019-07-01| Féminin|      Marié(e)| 81| 28|             6|    25-34|  6008.75|   71.5|    0.0|    0.0|     0.0|           0.0|            0.0|              0.0|         0.0|       0.0|            0.0|             0|                0|         1.0|                 0|              0|\n",
            "|  100004|2019-07-01|Masculin|   Celibataire| 81| 43|             6|    35-44|475151.82|    0.0|   6.67|    0.0|     0.0|           0.0|            0.0|          -6000.0|        0.67|    666.67|           0.33|             0|                0|         1.0|                 0|              0|\n",
            "|  100005|2019-10-01|Masculin|      Marié(e)| 90| 76|            20|      65+| -1756.49|    0.0|   0.67|    0.0|     0.0|           0.0|            0.0|              0.0|         0.0|       0.0|            0.0|             0|                0|         1.0|                 0|              0|\n",
            "|  100006|2019-10-01|Masculin|      Marié(e)| 90| 59|            20|    55-64|  5365.67| 767.41|    3.0|3333.33|    0.33|           0.0|            0.0|              0.0|         0.0|       0.0|            0.0|             0|                0|         1.0|                 0|              0|\n",
            "|  100006|2020-01-01|Masculin|      Marié(e)| 90| 59|            20|    55-64|  5121.42|    0.0|   3.33|3333.33|    0.33|           0.0|            0.0|          3333.33|        0.33|       0.0|            0.0|             0|                0|         1.0|                 0|              0|\n",
            "|  100008|2019-07-01|Masculin|   Celibataire| 90| 50|            24|    45-54|      0.0|    0.0|   3.33| 2553.9|    1.33|           0.0|            0.0|              0.0|         0.0|    3700.0|            6.0|             0|                0|         1.0|                 0|              0|\n",
            "|  100008|2019-10-01|Masculin|   Celibataire| 90| 50|            24|    45-54|      0.0|    0.0|   3.33|1515.42|    0.67|           0.0|            0.0|              0.0|         0.0|   2266.67|           2.67|             0|                0|         1.0|                 0|              0|\n",
            "|  100008|2020-01-01|Masculin|   Celibataire| 90| 50|            24|    45-54|      0.0|    0.0|   6.33|4366.67|    1.67|           0.0|            0.0|              0.0|         0.0|    2100.0|           3.33|             0|                0|         1.0|                 0|              0|\n",
            "|  100009|2019-07-01|Masculin|      Marié(e)| 90| 56|            22|    55-64|  7370.54|    0.0|   5.67|6733.33|    4.33|           0.0|            0.0|           2500.0|        3.67|       0.0|            0.0|             0|                0|         1.0|                 0|              0|\n",
            "|   10001|2019-04-01|Masculin|      Marié(e)| 64| 83|            43|      65+|  -391.31|    0.0|    0.0|    0.0|     0.0|           0.0|            0.0|              0.0|         0.0|       0.0|            0.0|             0|                0|         1.0|                 0|              0|\n",
            "|  100010|2019-10-01| Féminin|      Marié(e)| 90| 59|            22|    55-64|      0.0|    0.0|    3.0|9177.73|     1.0|           0.0|            0.0|        -13166.67|         2.0|    4000.0|           2.33|             0|                0|         1.0|                 0|              0|\n",
            "|  100010|2020-01-01| Féminin|      Marié(e)| 90| 59|            22|    55-64|      0.0|    0.0|   2.33|4255.53|    0.33|           0.0|            0.0|         -6166.67|         2.0|    666.67|           0.33|             0|                0|         1.0|                 0|              0|\n",
            "+--------+----------+--------+--------------+---+---+--------------+---------+---------+-------+-------+-------+--------+--------------+---------------+-----------------+------------+----------+---------------+--------------+-----------------+------------+------------------+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqviCDqxuxgF"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline(stages=indexers + encoders + [assembler])\n",
        "train = pipeline.fit(train).transform(train).withColumn(\"label\", col(\"Churn_next_trim\")).select(\"features\", \"label\")\n",
        "test = pipeline.fit(test).transform(test).withColumn(\"label\", col(\"Churn_next_trim\")).select(\"features\", \"label\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_count = train.groupBy(\"label\").count()\n",
        "class_count.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zftrgh6EsIfD",
        "outputId": "6b78ef50-7589-4ef2-ac75-efa840a52ac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+\n",
            "|label|  count|\n",
            "+-----+-------+\n",
            "|    1|   2520|\n",
            "|    0|2370146|\n",
            "+-----+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#class_count = master.groupBy(\"Churn_next_trim\").count().collect()\n",
        "#majority_count = max(class_count, key=lambda x: x['count' ]) ['count' ]\n",
        "#minority_count = min(class_count, key=lambda x: x['count' ]) ['count' ]"
      ],
      "metadata": {
        "id": "rn9UlGdRiyRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.sql.functions import when\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "class_count = master.groupBy(\"Churn_next_trim\").count().collect()\n",
        "\n",
        "majority_count = -1\n",
        "minority_count = float('inf')\n",
        "\n",
        "for row in class_count:\n",
        "    count_value = row['count']\n",
        "    if count_value > majority_count:\n",
        "        majority_count = count_value\n",
        "    if count_value < minority_count:\n",
        "        minority_count = count_value\n",
        "\n",
        "\n",
        "print(\"Majority count:\", majority_count)\n",
        "print(\"Minority count:\", minority_count)\n",
        "\n",
        "train_weighted = train.withColumn(\"classWeightCol\", when(train[\"label\"] == 1, majority_count/minority_count).otherwise(1.0))\n",
        "\n",
        "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", weightCol=\"classWeightCol\", maxIter=100)\n",
        "\n",
        "lr_model = lr.fit(train_weighted)\n",
        "\n",
        "predictions = lr_model.transform(test)\n",
        "\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
        "\n",
        "auc = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"AUC (Area Under ROC): {auc}\")\n",
        "\n",
        "print(f\"AUC: {auc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hvUINXOfaTc",
        "outputId": "3f94638d-a090-4034-92f0-4880bfdea32a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Majority count: 3388530\n",
            "Minority count: 3654\n",
            "AUC (Area Under ROC): 0.6175785813048541\n",
            "AUC: 0.6175785813048541\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "# Utiliser MulticlassClassificationEvaluator pour d'autres métriques\n",
        "multi_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
        "\n",
        "# Calculer la précision\n",
        "accuracy = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"accuracy\"})\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
        "\n",
        "# Calculer le rappel\n",
        "recall = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"weightedRecall\"})\n",
        "print(\"Recall: {:.2f}%\".format(recall * 100))\n",
        "\n",
        "# Calculer le F1-score\n",
        "f1_score = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"f1\"})\n",
        "print(\"F1 Score: {:.2f}%\".format(f1_score * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzKKtYhb6qL-",
        "outputId": "8412e65a-f401-4bf2-d874-57d930e613c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 58.36%\n",
            "Recall: 58.36%\n",
            "F1 Score: 73.61%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2eL_HJ44tSk"
      },
      "outputs": [],
      "source": [
        "# Create a DecisionTreeClassifier object\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", weightCol=\"classWeightCol\")\n",
        "# Fit the model to the training data\n",
        "dt_model = dt.fit(train_weighted)\n",
        "# Make predictions on the test data\n",
        "predictions = dt_model.transform(test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
        "\n",
        "auc = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"AUC (Area Under ROC): {auc}\")\n",
        "\n",
        "print(f\"AUC: {auc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4tg3xxP1JVE",
        "outputId": "6ee902e3-aef2-49fd-b17d-9ab9ef9b3e8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC (Area Under ROC): 0.5837954631992539\n",
            "AUC: 0.5837954631992539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "# Utiliser MulticlassClassificationEvaluator pour d'autres métriques\n",
        "multi_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
        "\n",
        "# Calculer la précision\n",
        "accuracy = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"accuracy\"})\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
        "\n",
        "# Calculer le rappel\n",
        "recall = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"weightedRecall\"})\n",
        "print(\"Recall: {:.2f}%\".format(recall * 100))\n",
        "\n",
        "# Calculer le F1-score\n",
        "f1_score = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"f1\"})\n",
        "print(\"F1 Score: {:.2f}%\".format(f1_score * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgcLFcJJ1PXf",
        "outputId": "bfdedb60-706a-41b2-d6e8-f330424338e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 63.31%\n",
            "Recall: 63.31%\n",
            "F1 Score: 77.43%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9GSxWKN_OEJ"
      },
      "outputs": [],
      "source": [
        "# Create a Gradient Boosted Trees classifier object\n",
        "from pyspark.ml.classification import GBTClassifier\n",
        "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\", weightCol=\"classWeightCol\", maxIter=100 , maxDepth=5, seed=42)\n",
        "# Fit the model to the training data\n",
        "gbt_model=gbt.fit(train_weighted)\n",
        "# Make predictions on the test data\n",
        "predictions=gbt_model. transform(test)\n",
        "\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
        "\n",
        "auc = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"AUC (Area Under ROC): {auc}\")\n",
        "\n",
        "print(f\"AUC: {auc}\")\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "# Utiliser MulticlassClassificationEvaluator pour d'autres métriques\n",
        "multi_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
        "\n",
        "# Calculer la précision\n",
        "accuracy = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"accuracy\"})\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
        "\n",
        "# Calculer le rappel\n",
        "recall = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"weightedRecall\"})\n",
        "print(\"Recall: {:.2f}%\".format(recall * 100))\n",
        "\n",
        "# Calculer le F1-score\n",
        "f1_score = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"f1\"})\n",
        "print(\"F1 Score: {:.2f}%\".format(f1_score * 100))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
        "# Define the Layers for the neural network\n",
        "featuresCol=\"features\"\n",
        "layers = [len(featuresCol), 10, 5, 2]\n",
        "# Create a MultilayerPerceptronClassifier object\n",
        "mlp = MultilayerPerceptronClassifier(labelCol=\"label\", featuresCol=\"features\", maxIter=100, layers=layers)\n",
        "# Fit the model to the training data\n",
        "mlp_model = mlp.fit(train_weighted)\n",
        "# Make predictions on the test data\n",
        "predictions = mlp_model.transform(test)"
      ],
      "metadata": {
        "id": "2KwLU3jmPD50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "# Utiliser MulticlassClassificationEvaluator pour d'autres métriques\n",
        "multi_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
        "\n",
        "# Calculer la précision\n",
        "accuracy = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"accuracy\"})\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
        "\n",
        "# Calculer le rappel\n",
        "recall = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"weightedRecall\"})\n",
        "print(\"Recall: {:.2f}%\".format(recall * 100))\n",
        "\n",
        "# Calculer le F1-score\n",
        "f1_score = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"f1\"})\n",
        "print(\"F1 Score: {:.2f}%\".format(f1_score * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TWqnWriyeqrv",
        "outputId": "69ba1143-de7d-463f-853c-bee33192c154"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "An error occurred while calling o3501.evaluate.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1660.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1660.0 (TID 4807) (86ea77bb676d executor driver): org.apache.spark.SparkException: [FAILED_EXECUTE_UDF] Failed to execute user defined function (`ProbabilisticClassificationModel$$Lambda$4565/0x0000000841815840`: (struct<type:tinyint,size:int,indices:array<int>,values:array<double>>) => struct<type:tinyint,size:int,indices:array<int>,values:array<double>>).\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.failedExecuteUserDefinedFunctionError(QueryExecutionErrors.scala:198)\n\tat org.apache.spark.sql.errors.QueryExecutionErrors.failedExecuteUserDefinedFunctionError(QueryExecutionErrors.scala)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:197)\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.lang.IllegalArgumentException: requirement failed: A & B Dimension mismatch!\n\tat scala.Predef$.require(Predef.scala:281)\n\tat org.apache.spark.ml.ann.BreezeUtil$.dgemm(BreezeUtil.scala:42)\n\tat org.apache.spark.ml.ann.AffineLayerModel.eval(Layer.scala:164)\n\tat org.apache.spark.ml.ann.FeedForwardModel.forward(Layer.scala:508)\n\tat org.apache.spark.ml.ann.FeedForwardModel.predictRaw(Layer.scala:561)\n\tat org.apache.spark.ml.classification.MultilayerPerceptronClassificationModel.predictRaw(MultilayerPerceptronClassifier.scala:337)\n\tat org.apache.spark.ml.classification.MultilayerPerceptronClassificationModel.predictRaw(MultilayerPerceptronClassifier.scala:279)\n\tat org.apache.spark.ml.classification.ProbabilisticClassificationModel.$anonfun$transform$2(ProbabilisticClassifier.scala:121)\n\t... 22 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2458)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1049)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1048)\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$collectAsMap$1(PairRDDFunctions.scala:738)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\n\tat org.apache.spark.rdd.PairRDDFunctions.collectAsMap(PairRDDFunctions.scala:737)\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.confusions$lzycompute(MulticlassMetrics.scala:61)\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.confusions(MulticlassMetrics.scala:52)\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.tpByClass$lzycompute(MulticlassMetrics.scala:78)\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.tpByClass(MulticlassMetrics.scala:76)\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.accuracy$lzycompute(MulticlassMetrics.scala:188)\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.accuracy(MulticlassMetrics.scala:188)\n\tat org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator.evaluate(MulticlassClassificationEvaluator.scala:153)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: org.apache.spark.SparkException: [FAILED_EXECUTE_UDF] Failed to execute user defined function (`ProbabilisticClassificationModel$$Lambda$4565/0x0000000841815840`: (struct<type:tinyint,size:int,indices:array<int>,values:array<double>>) => struct<type:tinyint,size:int,indices:array<int>,values:array<double>>).\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.failedExecuteUserDefinedFunctionError(QueryExecutionErrors.scala:198)\n\tat org.apache.spark.sql.errors.QueryExecutionErrors.failedExecuteUserDefinedFunctionError(QueryExecutionErrors.scala)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:197)\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\nCaused by: java.lang.IllegalArgumentException: requirement failed: A & B Dimension mismatch!\n\tat scala.Predef$.require(Predef.scala:281)\n\tat org.apache.spark.ml.ann.BreezeUtil$.dgemm(BreezeUtil.scala:42)\n\tat org.apache.spark.ml.ann.AffineLayerModel.eval(Layer.scala:164)\n\tat org.apache.spark.ml.ann.FeedForwardModel.forward(Layer.scala:508)\n\tat org.apache.spark.ml.ann.FeedForwardModel.predictRaw(Layer.scala:561)\n\tat org.apache.spark.ml.classification.MultilayerPerceptronClassificationModel.predictRaw(MultilayerPerceptronClassifier.scala:337)\n\tat org.apache.spark.ml.classification.MultilayerPerceptronClassificationModel.predictRaw(MultilayerPerceptronClassifier.scala:279)\n\tat org.apache.spark.ml.classification.ProbabilisticClassificationModel.$anonfun$transform$2(ProbabilisticClassifier.scala:121)\n\t... 22 more\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-999d2d470dac>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Calculer la précision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_evaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mmulti_evaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetricName\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy: {:.2f}%\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/evaluation.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/evaluation.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0misLargerBetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o3501.evaluate.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1660.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1660.0 (TID 4807) (86ea77bb676d executor driver): org.apache.spark.SparkException: [FAILED_EXECUTE_UDF] Failed to execute user defined function (`ProbabilisticClassificationModel$$Lambda$4565/0x0000000841815840`: (struct<type:tinyint,size:int,indices:array<int>,values:array<double>>) => struct<type:tinyint,size:int,indices:array<int>,values:array<double>>).\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.failedExecuteUserDefinedFunctionError(QueryExecutionErrors.scala:198)\n\tat org.apache.spark.sql.errors.QueryExecutionErrors.failedExecuteUserDefinedFunctionError(QueryExecutionErrors.scala)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:197)\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.lang.IllegalArgumentException: requirement failed: A & B Dimension mismatch!\n\tat scala.Predef$.require(Predef.scala:281)\n\tat org.apache.spark.ml.ann.BreezeUtil$.dgemm(BreezeUtil.scala:42)\n\tat org.apache.spark.ml.ann.AffineLayerModel.eval(Layer.scala:164)\n\tat org.apache.spark.ml.ann.FeedForwardModel.forward(Layer.scala:508)\n\tat org.apache.spark.ml.ann.FeedForwardModel.predictRaw(Layer.scala:561)\n\tat org.apache.spark.ml.classification.MultilayerPerceptronClassificationModel.predictRaw(MultilayerPerceptronClassifier.scala:337)\n\tat org.apache.spark.ml.classification.MultilayerPerceptronClassificationModel.predictRaw(MultilayerPerceptronClassifier.scala:279)\n\tat org.apache.spark.ml.classification.ProbabilisticClassificationModel.$anonfun$transform$2(ProbabilisticClassifier.scala:121)\n\t... 22 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2458)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1049)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1048)\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$collectAsMap$1(PairRDDFunctions.scala:738)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\n\tat org.apache.spark.rdd.PairRDDFunctions.collectAsMap(PairRDDFunctions.scala:737)\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.confusions$lzycompute(MulticlassMetrics.scala:61)\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.confusions(MulticlassMetrics.scala:52)\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.tpByClass$lzycompute(MulticlassMetrics.scala:78)\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.tpByClass(MulticlassMetrics.scala:76)\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.accuracy$lzycompute(MulticlassMetrics.scala:188)\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.accuracy(MulticlassMetrics.scala:188)\n\tat org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator.evaluate(MulticlassClassificationEvaluator.scala:153)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: org.apache.spark.SparkException: [FAILED_EXECUTE_UDF] Failed to execute user defined function (`ProbabilisticClassificationModel$$Lambda$4565/0x0000000841815840`: (struct<type:tinyint,size:int,indices:array<int>,values:array<double>>) => struct<type:tinyint,size:int,indices:array<int>,values:array<double>>).\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.failedExecuteUserDefinedFunctionError(QueryExecutionErrors.scala:198)\n\tat org.apache.spark.sql.errors.QueryExecutionErrors.failedExecuteUserDefinedFunctionError(QueryExecutionErrors.scala)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:197)\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\nCaused by: java.lang.IllegalArgumentException: requirement failed: A & B Dimension mismatch!\n\tat scala.Predef$.require(Predef.scala:281)\n\tat org.apache.spark.ml.ann.BreezeUtil$.dgemm(BreezeUtil.scala:42)\n\tat org.apache.spark.ml.ann.AffineLayerModel.eval(Layer.scala:164)\n\tat org.apache.spark.ml.ann.FeedForwardModel.forward(Layer.scala:508)\n\tat org.apache.spark.ml.ann.FeedForwardModel.predictRaw(Layer.scala:561)\n\tat org.apache.spark.ml.classification.MultilayerPerceptronClassificationModel.predictRaw(MultilayerPerceptronClassifier.scala:337)\n\tat org.apache.spark.ml.classification.MultilayerPerceptronClassificationModel.predictRaw(MultilayerPerceptronClassifier.scala:279)\n\tat org.apache.spark.ml.classification.ProbabilisticClassificationModel.$anonfun$transform$2(ProbabilisticClassifier.scala:121)\n\t... 22 more\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbEUuszXkokG"
      },
      "outputs": [],
      "source": [
        "#Count the number of records for each class in the DataFrame using the groupBy and count functions.\n",
        "class_count = master.groupBy('Churn_next_trim').count().collect()\n",
        "#Determine the class with the smallest number of records.\n",
        "smallest_class_count = min(class_count, key=lambda x: x['count' ]) ['count' ]\n",
        "# Calculate the number of records needed for each class to achieve balance\n",
        "target_count = min(class_count, key=lambda x: x['count']) ['count' ]\n",
        "# Calculate the sampling fractions for oversampling the minority class\n",
        "sampling_fractions = {k: min(target_count / v, 1.0) for k, v in dict(class_count).items() if v < target_count}\n",
        "# Oversample the minority class\n",
        "oversampled_df = master. sampleBy('Churn_next_trim', fractions=sampling_fractions, seed=42)\n",
        "# Calculate the sampling fractions for undersampling the majority clas\n",
        "sampling_fractions = {k: 1.0 if v == smallest_class_count else target_count / v for k, v in dict(class_count).items()}\n",
        "# Undersample the majority class\n",
        "undersampled_df = master.sampleBy('Churn_next_trim', fractions=sampling_fractions, seed=42)\n",
        "balanced_df = oversampled_df.unionAll(undersampled_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JANNYbfgC9k",
        "outputId": "89f8ad05-56d2-4578-80c4-c117630e7746"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+-----+\n",
            "|Churn_next_trim|count|\n",
            "+---------------+-----+\n",
            "|              1| 3654|\n",
            "|              0| 3707|\n",
            "+---------------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Compter le nombre d'enregistrements pour chaque classe dans le DataFrame équilibré\n",
        "final_class_count = balanced_df.groupBy('Churn_next_trim').count()\n",
        "\n",
        "# Afficher le résultat\n",
        "final_class_count.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuImAtr1wFyP",
        "outputId": "82af54ac-8203-44b2-c963-d3a7ad2dc570"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC: 61.15%\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "# Define the model\n",
        "lr= LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "# Train the model\n",
        "lr_model = lr.fit(train)\n",
        "# Evaluate the model\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\")\n",
        "predictions = lr_model.transform(test)\n",
        "LRauc = evaluator.evaluate(predictions)\n",
        "print(\"AUC: {:.2f}%\".format(LRauc * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qURYQT9-ywN2",
        "outputId": "91dd3531-16ce-4d93-b85e-631c06731882"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 58.34%\n",
            "Recall: 58.34%\n",
            "F1 Score: 58.34%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Utiliser MulticlassClassificationEvaluator pour d'autres métriques\n",
        "multi_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
        "\n",
        "# Calculer la précision\n",
        "accuracy = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"accuracy\"})\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
        "\n",
        "# Calculer le rappel\n",
        "recall = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"weightedRecall\"})\n",
        "print(\"Recall: {:.2f}%\".format(recall * 100))\n",
        "\n",
        "# Calculer le F1-score\n",
        "f1_score = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"f1\"})\n",
        "print(\"F1 Score: {:.2f}%\".format(f1_score * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riBuICcV4l2O",
        "outputId": "40c32b75-adb0-4796-c986-5872d015ef87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 58.35%\n"
          ]
        }
      ],
      "source": [
        "precision = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"weightedPrecision\"})\n",
        "print(\"Precision: {:.2f}%\".format(precision * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6n--D5AQ1Qt5",
        "outputId": "c1cad24d-51d9-4254-9ddd-7fdc5c18bb94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC: 54.13%\n"
          ]
        }
      ],
      "source": [
        "LRauc = evaluator.evaluate(predictions)\n",
        "print(\"AUC: {:.2f}%\".format(LRauc * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXdv-C5S6pCZ",
        "outputId": "c1a98087-e253-4de1-95d1-828f6ca32194"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 99.89%\n",
            "Recall: 99.89%\n",
            "F1 Score: 99.83%\n"
          ]
        }
      ],
      "source": [
        "# Utiliser MulticlassClassificationEvaluator pour d'autres métriques\n",
        "multi_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
        "\n",
        "# Calculer la précision\n",
        "accuracy = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"accuracy\"})\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
        "\n",
        "# Calculer le rappel\n",
        "recall = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"weightedRecall\"})\n",
        "print(\"Recall: {:.2f}%\".format(recall * 100))\n",
        "\n",
        "# Calculer le F1-score\n",
        "f1_score = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"f1\"})\n",
        "print(\"F1 Score: {:.2f}%\".format(f1_score * 100))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LRauc = evaluator.evaluate(predictions)\n",
        "print(\"AUC: {:.2f}%\".format(LRauc * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FT_aYBP_GYcp",
        "outputId": "5c63332a-39d8-4efc-b8a7-162db1d17842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC: 62.92%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Utiliser MulticlassClassificationEvaluator pour d'autres métriques\n",
        "multi_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
        "\n",
        "# Calculer la précision\n",
        "accuracy = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"accuracy\"})\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
        "\n",
        "# Calculer le rappel\n",
        "recall = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"weightedRecall\"})\n",
        "print(\"Recall: {:.2f}%\".format(recall * 100))\n",
        "\n",
        "# Calculer le F1-score\n",
        "f1_score = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"f1\"})\n",
        "print(\"F1 Score: {:.2f}%\".format(f1_score * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrES1dngGcUa",
        "outputId": "5bb0f91d-dbc1-4384-f89f-c463f5a82434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 59.43%\n",
            "Recall: 59.43%\n",
            "F1 Score: 59.39%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vérifier si certaines lignes contiennent des valeurs nulles\n",
        "train.filter(train.features.isNull() | train.label.isNull()).show()\n",
        "\n",
        "# Optionnel : supprimer les lignes avec des valeurs nulles\n",
        "train_clean = train.na.drop()\n",
        "test_clean = test.na.drop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldyYziLQxeOg",
        "outputId": "7ccf1b3b-75b0-46f4-92e9-801bcc2c8903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+\n",
            "|features|label|\n",
            "+--------+-----+\n",
            "+--------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.count()\n",
        "test.count()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBXfEAD75_qI",
        "outputId": "f8f00ba0-8f69-4ca7-a6d3-939b364a4c0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2201"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOkMnswWYJ0V0mckrekHe1y",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}